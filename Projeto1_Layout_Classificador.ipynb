{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Camila Soares Magni\n",
    "\n",
    "Nome: Lincoln Rodrigo Pereira Melo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "c:\\Users\\Lincoln\\Desktop\\Mat√©rias2021.2\\Cdados\\LAST\\Proj1Cdados\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "filename = 'airfryer.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train = train.dropna(axis=1)\r\n",
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o twitter vai me fazer comprar uma airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o de queijo, mas o forno daqui d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom, aparentemente deu ruim e saiu toda a tint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de airfryer a panelas: polishop celebra 22 ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@danielsmarconn mano eu t√¥ louca nessa airfrye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0        o twitter vai me fazer comprar uma airfryer              1\n",
       "1  quero assar p√£o de queijo, mas o forno daqui d...              1\n",
       "2  bom, aparentemente deu ruim e saiu toda a tint...              1\n",
       "3  de airfryer a panelas: polishop celebra 22 ano...              0\n",
       "4  @danielsmarconn mano eu t√¥ louca nessa airfrye...              1"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o bom da airfryer fica tudo pronto r√°pido, n√£o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um app pra calcular se √© mais barato fazer a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@raytotsukishiro aumentou o pre√ßo de tudo. aqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti um p√£o de queijo na airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@alcysio @safbf p√¥ alcysio, me adaptei total p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  o bom da airfryer fica tudo pronto r√°pido, n√£o...              1\n",
       "1  um app pra calcular se √© mais barato fazer a c...              0\n",
       "2  @raytotsukishiro aumentou o pre√ßo de tudo. aqu...              0\n",
       "3                meti um p√£o de queijo na airfryer üòå              1\n",
       "4  @alcysio @safbf p√¥ alcysio, me adaptei total p...              1"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SOBRE O PRODUTO\n",
    "\n",
    "O produto escolhido foi a AirFryer : \"AirFryer ou air fryer √© um eletrodom√©stico usado para fritar alimentos. √â t√£o eficaz quanto uma fritadeira tradicional que usa √≥leo, mas n√£o utiliza a imers√£o em gorduras para a coc√ß√£o/para o cozimento dos alimentos.\"\n",
    "\n",
    "fonte : https://pt.wikipedia.org/wiki/Fritadeira_sem_%C3%B3leo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\r\n",
    "\r\n",
    "A partir da escolha do produto, foram considerados relevantes os tweets que expressam algum sentimento, seja positivo ou negativo, al√©m de mensagens que demonstram vontade de adquirir o produto ou receitas que os usu√°rios compartilham.\r\n",
    "O restante dos tweets foi considerado irrelevante, incluindo aqueles que utilizam o termo \"airfryer\" em outros contextos n√£o relacionados diretamente ao produto (Por exemplo, \"Parece que estou dentro de uma airfryer\").\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador multinomial Na√Øve Bayes √© um dos modelos mais populares no aprendizado de m√°quina. Tomando como premissa a suposi√ß√£o de independ√™ncia entre as vari√°veis do problema, o modelo de Na√Øve Bayes realiza uma classifica√ß√£o probabil√≠stica de observa√ß√µes, caracterizando-as em classes pr√©-definidas. \r\n",
    "\r\n",
    "\r\n",
    "O algoritmo Na√Øve Bayes √© uma aplica√ß√£o direta do teorema hom√¥nimo. O termo na√Øve, (do ingl√™s, ing√™nuo) se refere √† premissa central do algoritmo de que os atributos considerados s√£o n√£o correlacionados entre si. \r\n",
    "\r\n",
    "fonte : https://www.digitalhouse.com/br/blog/naive-bayes\r\n",
    "\r\n",
    "\r\n",
    "Por exemplo, no classificador aqui montado, n√£o s√£o levada em contas express√µes e apenas as palavras isoladas.\r\n",
    "\r\n",
    "\r\n",
    "Explicando um pouco da constru√ß√£o do classificador:\r\n",
    "\r\n",
    "#### Eventos:\r\n",
    "$R$:   tweets relevantes\r\n",
    "\r\n",
    "$R^C$: tweets irrelevantes\r\n",
    "\r\n",
    "$U$ :  todos os tweets relacionados com airfryer coletados\r\n",
    "\r\n",
    "$P(R)$ -> Probabilidade de um tweet ser relevante\r\n",
    "\r\n",
    "$P(R^C)$ -> Probabilidade de um tweet ser irrelevante\r\n",
    "\r\n",
    "$P(R/Tweet)$ -> Probabilidade de ser relevante dado que √© um tweet relacionado com airfryer\r\n",
    "\r\n",
    "$P(R^C/Tweet)$ -> Probabilidade de ser irrelevante dado que √© um tweet relacionado com airfryer\r\n",
    "\r\n",
    "Lembre-se que $P(A/B) = P(B/A) * P(A) / P(B)$\r\n",
    "\r\n",
    "Note que ao utilizar Naive-Bayes, queremos apenas classificar como relevante ou irrelevante, ou seja \r\n",
    "saber se P(R/Tweet) > P(R^C/Tweet) ou P(R^C/Tweet) > P(R/Tweet):\r\n",
    "Se calcularmos :\r\n",
    "$P(R/Tweet) = P(Tweet/R) * P(R) / P(Tweet)$   (i)\r\n",
    "\r\n",
    "e\r\n",
    "\r\n",
    "$P(R^C/Tweet) = P(Tweet/R^c) * P(R^c) / P(Tweet)$ (ii)\r\n",
    "\r\n",
    "Como queremos apenas a compara√ß√£o entre (i) e (ii), podemos desconsiderar os denominadores na conta\r\n",
    "Portanto, para esse caso usaremos:\r\n",
    "\r\n",
    "$P(R/Tweet) = P(Tweet/R) * P(R)$\r\n",
    "\r\n",
    "$P(R^C/Tweet) = P(Tweet/R^c) * P(R^c)$\r\n",
    "\r\n",
    "Com isso, olhando para a $P(Tweet/R) e P(Tweet/R^c).$\r\n",
    "\r\n",
    "Considerando Tweet = palavra1 palavra2 palavra3\r\n",
    "\r\n",
    "A nossa $P(Tweet/R) = P(palavra1/R) * P(palavra2/R) * P(palavra3/R)$\r\n",
    "\r\n",
    "e \r\n",
    "$P(Tweet/R^C) = P(palavra1/R^C) * P(palavra2/R^C) * P(palavra3/R^C)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suaviza√ß√£o de LaPlace:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seguindo a linha de racioc√≠nio de Naive-Bayes, caso uma palavra n√£o esteja presente no conjunto de palavras analisados, ent√£o ter√≠amos:\n",
    "\n",
    "$P(palavra/R)$ = 0\n",
    "\n",
    "e\n",
    "\n",
    "$P(palavra/R^C)$ = 0.\n",
    "\n",
    "Portanto se essa palavra estivesse em qualquer frase, a probabilidade dessa frase ser classificada seria zero.\n",
    "\n",
    "Para resolver essa situa√ß√£o surgiu a Suaviza√ß√£o de Laplace. Essa ideia se baseia em adicionar um em cada contagem para que o resultado do numerador nunca seja igual a zero. Al√©m disso, adicionar o n√∫mero de palavras poss√≠veis no denominador para balancear e garantir que a divis√£o nunca vai ser maior do que 1.\n",
    "\n",
    "Note que essa ideia ser√° aplicada na implementa√ß√£o da fun√ß√£o."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fun√ß√µes para a limpeza da base de dados:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from IPython.display import display\r\n",
    "import re \r\n",
    "import nltk\r\n",
    "\r\n",
    "# Fun√ß√£o de limpeza dos textos\r\n",
    "def cleanup(text):\r\n",
    "    punctuation = '[\"\"''!-.:?;‚Äú‚Äù~1234567890]'                            # sinais que queremos retirar do texto\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)                              # retira os sinais\r\n",
    "    text_subbed = re.sub(r\"http\\S+\", \"\", text_subbed)                    # retira os URL\r\n",
    "    text_subbed = re.sub('@[^\\s]+','',text_subbed,flags=re.MULTILINE)    # retira os nomes de usu√°rio\r\n",
    "    text_subbed = re.sub(r\"kk\\S+\", \"kk\", text_subbed)                    # transforma as strings que come√ßam com kk em 'kk'\r\n",
    "    text_subbed = re.sub(r\"compr\\S+\", \"compr\", text_subbed)              # transforma as strings que come√ßam com compr (radical do verbo comprar) em \"compr\"\r\n",
    "    text_subbed = re.sub(r\"limp\\S+\", \"limp\", text_subbed)                # transforma as strings que come√ßam com limp (radical do verbo limpar) em \"limp\"\r\n",
    "    text_subbed = re.sub(r\"aa\\S+\", \"\", text_subbed)                      # retira as strings que come√ßam com aa (normalmente alguma express√£o ou sequ√™ncia de letras sem sentido)\r\n",
    "    text_subbed = re.sub(r\"airfryer\\S+\", \"airfryer\", text_subbed)        # usado evitar que erros de escrita de palavras coladas com airfryer n√£o acontecam\r\n",
    "    text_subbed = re.sub(r\"queij\\S+\", \"queij\", text_subbed)              # para corrigir alguns erros de portugu√™s comuns dos usu√°rios dos tweets (receita recorrente)\r\n",
    "    text_subbed = re.sub(r\"batat\\S+\", \"batata\", text_subbed)             # transforma as strings que come√ßam com batat (radical da palavra batata) para evitar varia√ß√µes como \"Batatinhas\"\r\n",
    "    aux = nltk.TweetTokenizer()\r\n",
    "    text_subbed = aux.tokenize(text_subbed)                              # separa os emojis\r\n",
    "    string_final = ' '.join(text_subbed)                                 # string limpa\r\n",
    "    return string_final"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Fun√ß√£o para tirar as 'Stopwords' em portugu√™s:\r\n",
    "# nltk.download('stopwords') - INSTALAR, caso vc n√£o tenha instalado\r\n",
    "def retirar_stopwords(lista):\r\n",
    "    lista_limpa = []\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    for palavra in lista:\r\n",
    "        if palavra not in stopwords:\r\n",
    "            lista_limpa.append(palavra)\r\n",
    "    return lista_limpa"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realizando a limpeza da base de treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "lista = []\r\n",
    "for linha in train['Treinamento']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b)  \r\n",
    "    lista.append(limpo)\r\n",
    "    \r\n",
    "serie_train = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\r\n",
    "train['Treinamento'] = serie_train        # substitui os tweets originais da planilha, pelos tweets limpos\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fun√ß√£o Classificadora Naive-Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na C√©lula abaixo est√° implementada a fun√ß√£o classificadora Naive-Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def classificador(dataframe, series):                         #recebe o dataframe e a serie de tweets que ser√° classificada\r\n",
    "    \r\n",
    "    filtro = train.Classifica√ß√£o==1          # filtra os tweets classificados como relevantes\r\n",
    "    relevantes = train.loc[filtro, :]        # dataframe com tweets relevantes\r\n",
    "\r\n",
    "    filtro2 = train.Classifica√ß√£o==0        # filtra os tweets classificados como irrelevantes\r\n",
    "    irrelevantes = train.loc[filtro2, :]    # dataframe com tweets irrelevantes\r\n",
    "\r\n",
    "    # Transforma o dataframe relevantes em um √∫nico texto\r\n",
    "    string_relevante = ''\r\n",
    "    for linha in relevantes.iloc[:,0]:\r\n",
    "        string_relevante+= ' '+ linha\r\n",
    "\r\n",
    "    # Transforma o dataframe irrelevantes em um √∫nico texto\r\n",
    "    string_irrelevante = ''\r\n",
    "    for linha in irrelevantes.iloc[:,0]:\r\n",
    "        string_irrelevante+= ' '+ linha\r\n",
    "\r\n",
    "    todas_relevantes = string_relevante.split()        #Lista com todas as palavras que aparece na string relevante\r\n",
    "    todas_irrelevantes = string_irrelevante.split()    #Lista com todas as palavras que aparece na string irrelevante\r\n",
    "\r\n",
    "    serie_relevante = pd.Series(todas_relevantes)      #Transforma a lista de strings relevantes em um series\r\n",
    "    serie_irrelevante = pd.Series(todas_irrelevantes)  #Transforma a lista de strings irrelevantes em um series\r\n",
    "\r\n",
    "    todas = string_irrelevante + string_relevante          # juntando todas as palavras que aparecem na base de dados Treinamento\r\n",
    "    todas_as_palavras = todas.split()                      # lista com todas as palavras\r\n",
    "    serie_total = pd.Series(todas_as_palavras) \r\n",
    "    serie_total\r\n",
    "\r\n",
    "    P_R = len(todas_relevantes)/len(todas_as_palavras)        # probabilidade de uma palavra ser relevante\r\n",
    "    P_I = len(todas_irrelevantes)/len(todas_as_palavras)      # probabilidade de uma palavra ser irrelevante\r\n",
    "\r\n",
    "    freq_rel_absoluta = serie_relevante.value_counts()           # quantidade de cada palavra na serie relevante\r\n",
    "    freq_irrel_absoluta = serie_irrelevante.value_counts()       # quantidade de cada palavra na serie irrelevante\r\n",
    "    freq_tot_absoluta = serie_total.value_counts()               # quantidade de cada palavra na serie total\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "    classificados = []\r\n",
    "    for frase in series:\r\n",
    "        lista_palavras = frase.split()\r\n",
    "        lista_palavras = retirar_stopwords(lista_palavras)    #implementa fun√ß√£o que tira as stopwords\r\n",
    "        k,i = 0,0                                             #contador de palavras N√ÉO presentes em relevantes (k) e em irrevelantes (i)\r\n",
    "        for palavra in lista_palavras:\r\n",
    "            if palavra not in todas_relevantes: \r\n",
    "                k += 1\r\n",
    "            if palavra not in todas_irrelevantes:\r\n",
    "                i += 1\r\n",
    "\r\n",
    "        prob_frase_dado_relevante = 1\r\n",
    "        prob_frase_dado_irrelevante = 1\r\n",
    "\r\n",
    "        if k == 0:                                   #se tiver palavras no series que n√£o estao na nossa base de dados relevantes\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                prob = freq_rel_absoluta[palavra] / freq_rel_absoluta.sum()\r\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\r\n",
    "\r\n",
    "        else:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                if palavra in freq_rel_absoluta:\r\n",
    "                    prob = (freq_rel_absoluta[palavra]+ 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta)) # SUAVIZA√á√ÉO DE LAPLACE\"\r\n",
    "                else: \r\n",
    "                    prob = (0 + 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta))\r\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\r\n",
    "        \r\n",
    "        if i == 0:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                prob = ( freq_irrel_absoluta[palavra] ) / (freq_irrel_absoluta.sum())\r\n",
    "                prob_frase_dado_irrelevante *= prob     \r\n",
    "\r\n",
    "        else:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                if palavra in freq_irrel_absoluta:\r\n",
    "                    prob = ( freq_irrel_absoluta[palavra]+ 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\r\n",
    "                else:\r\n",
    "                    prob = ( 0 + 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\r\n",
    "                prob_frase_dado_irrelevante *= prob         #multiplica a probabilidade de cada palavra dado frase\r\n",
    "                #multiplica a probabilidade de cada palavra dado frase\r\n",
    "                \r\n",
    "        probRdadoFrase = prob_frase_dado_relevante* P_R\r\n",
    "        probIdadoFrase = prob_frase_dado_irrelevante* P_I\r\n",
    "        \r\n",
    "        if probRdadoFrase > probIdadoFrase:\r\n",
    "            classificados.append(1)                         #classifica como relevante\r\n",
    "        else:  \r\n",
    "            classificados.append(0)                         #classifica como irrelevante\r\n",
    "    \r\n",
    "    serie_classificado = pd.Series(classificados)\r\n",
    "    novo_df = dataframe.iloc[:, [0,1]]\r\n",
    "    novo_df = novo_df.reset_index(drop=True)\r\n",
    "    novo_df['Classificado'] = serie_classificado\r\n",
    "    return novo_df\r\n",
    "                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fazendo a limpeza na base de teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "lista = []\r\n",
    "\r\n",
    "for linha in test['Teste']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Teste e tira as letras mai√∫sculas\r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b)  \r\n",
    "    lista.append(limpo)\r\n",
    "\r\n",
    "test['Teste'] = pd.Series(lista)             # Substitui os tweets originais da planilha, pelos tweets limpos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementando a fun√ß√£o..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "df = test               # dataframe que ser√° argumento da fun√ß√£o classificadora\r\n",
    "series= test['Teste']   # series que ser√° argumento da fun√ß√£o classificadora"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Implementa fun√ß√£o\r\n",
    "df = classificador(df, series) #dataframe que passou pelo fun√ß√£o para classificar os tweets\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bom airfryer fica tudo pronto r√°pido quero out...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app pra calcular barato fazer comida airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aumentou pre√ßo tudo aqui gente compr airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti p√£o queij airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0  bom airfryer fica tudo pronto r√°pido quero out...              1   \n",
       "1  app pra calcular barato fazer comida airfryer ...              0   \n",
       "2  aumentou pre√ßo tudo aqui gente compr airfryer ...              0   \n",
       "3                          meti p√£o queij airfryer üòå              1   \n",
       "4  p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...              1   \n",
       "\n",
       "   Classificado  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extraindo as contagens para verifica√ß√£o de performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "tabela = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)  # tabela de porcentagens\r\n",
    "tabela"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificado</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classifica√ß√£o     0      1\n",
       "Classificado              \n",
       "0              0.28  0.095\n",
       "1              0.17  0.455"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros positivos (mensagens relevantes e que s√£o\n",
    "classificadas como relevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "verdadeiros_positivos = tabela.iloc[1,1]*100\r\n",
    "verdadeiros_positivos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45.5"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos positivos (mensagens irrelevantes e que s√£o classificadas\n",
    "como relevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "falsos_positivos = tabela.iloc[1,0]*100\r\n",
    "falsos_positivos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros negativos (mensagens irrelevantes e que s√£o\n",
    "classificadas como irrelevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "verdadeiros_negativos = tabela.iloc[0,0]*100\r\n",
    "verdadeiros_negativos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28.000000000000004"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos negativos (mensagens relevantes e que s√£o classificadas\n",
    "como irrelevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "falsos_negativos = tabela.iloc[0,1]*100\r\n",
    "falsos_negativos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Acur√°cia (mensagens corretamente classificadas, independente da categoria)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "acuracia = verdadeiros_positivos + verdadeiros_negativos\r\n",
    "acuracia"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "73.5"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance do classificador e poss√≠veis melhorias  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparativo qualitativo sobre os percentuais obtidos:\r\n",
    "\r\n",
    "A partir dos percentuais de verdadeiros positivos e negativos obtidos, observa-se que o nosso classificador possui acur√°cia de 73.5%, o que significa que dos 100% dos tweets, ter√≠amos 26.5% de falhas (falsos positivos e negativos).\r\n",
    "\r\n",
    "Analisando de maneira mais aprofundada todos os tweets classificados como relevantes (62.5% do total), temos que a porcentagem de verdadeiros positivos (45.5%) √© mais que o dobro do que a de falsos positivos (17%). Em outras palavras, 72.8% dos tweets classificados como relevantes, foram classificados corretamente. \r\n",
    "\r\n",
    "Da mesma forma, olhando para os tweets classificados como irrelevantes (37.5% do total, temos 28% de acertos, ou seja, 74,6% dos tweets classificados como irrelevantes.\r\n",
    "\r\n",
    "As mensagens com sarcasmo ou dupla nega√ß√£o s√£o tratadas pelo classificador da mesma forma que qualquer outra mensagem, isto √©, pela an√°lise das probabilidades de cada palavra do tweet. Ent√£o, algumas s√£o classificadas corretamente e outras, n√£o, j√° que muitas palavras aparecem na Base de Treinamento como relevantes. \r\n",
    "\r\n",
    "Dessa forma, levando em considera√ß√£o os percentuais obtidos, consideramos que a performance do nosso classificador est√° aceit√°vel, por√©m h√° algumas melhorias que poderiam ser implementadas, como a ideia trazida no artigo \"Melhorando a Performance do Algoritmo Naive Bayes para Regress√£o Atrav√©s da Combina√ß√£o de Atributos \" de Alo√≠sio Carlos de Pina e de Gerson Zaverucha. Eles trazem uma ideia de  testar combina√ß√µes de atributos dentro do cl√°ssico Naive Bayes, onde transformariam os atributos A1 e A2 em um √∫nico atributo C' e caso houvesse melhora utilizando esse novo atributo C' ele seria mantido. Trazendo para a situa√ß√£o do projeto, seria a ideia de testar todas as poss√≠veis combina√ß√µes de duas palavras e aquelas que melhorassem o desempenho do nosso classificador seria mantida.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "fonte : https://www.cos.ufrj.br/~ines/enia07_html/pdf/28095.pdf\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Por que continuar financiando o projeto? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O projeto deve continuar sendo financiado, porque a partir dele, √© poss√≠vel entender os interesses e as opini√µes do p√∫blico alvo da empresa, assim como elogios e cr√≠ticas ao produto, para que seja poss√≠vel implementar melhorias em pontos com maiores reclama√ß√µes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se n√≥s alimentarmos a base de Treinamento utilizando o pr√≥prio classificador, o percentual de erros aumentaria significativamente. Isso porque, os erros do classificador se propagariam para a classifica√ß√£o da base Treinamento, que por sua vez, alimentaria a classifica√ß√£o de novas bases, propagando cada vez mais os erros, o que tornaria o modelo cada vez mais impreciso"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Diferentes cen√°rios de uso para o classificador Naive-Bayes "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador Naive-Bayes pode ser aplicado em diversas situa√ß√µes diferentes, como no diagn√≥stico de doen√ßas ( Considerando os verdadeiros (positivos e negativos) e falsos (positivos e negativos) , na identifica√ß√£o de mensagens de spam nos emails, protegendo os usu√°rios de um poss√≠vel golpe e otimizando o tempo passado no email e  numa alimenta√ß√£o de um algoritmo para sugerir conte√∫do baseado nas palavras buscadas pelo usu√°rio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "test = pd.read_excel(filename, sheet_name = \"Teste\" )\r\n",
    "test_novo_tudo = test.rename(columns={ \"Teste\" : \"Tudo\"})\r\n",
    "\r\n",
    "train = pd.read_excel(filename,sheet_name = \"Treinamento\")\r\n",
    "train_novo_tudo = train.rename(columns={ \"Treinamento\" : \"Tudo\" })\r\n",
    "\r\n",
    "df_tudo = pd.concat([train_novo_tudo,test_novo_tudo])\r\n",
    "df_tudo = df_tudo.dropna(axis=1)\r\n",
    "df_tudo"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o twitter vai me fazer comprar uma airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o de queijo, mas o forno daqui d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom, aparentemente deu ruim e saiu toda a tint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de airfryer a panelas: polishop celebra 22 ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@danielsmarconn mano eu t√¥ louca nessa airfrye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>pessoal daqui de casa inventou de querer fazer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu nao sei voces, mas eu ganhei uma airfryer g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@ibebelly amanh√£ eu vou fazer um p√£o de alho d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>disse pra vov√≥ que t√¥ estagiando e a mulher j√°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tudo  Classifica√ß√£o\n",
       "0          o twitter vai me fazer comprar uma airfryer              1\n",
       "1    quero assar p√£o de queijo, mas o forno daqui d...              1\n",
       "2    bom, aparentemente deu ruim e saiu toda a tint...              1\n",
       "3    de airfryer a panelas: polishop celebra 22 ano...              0\n",
       "4    @danielsmarconn mano eu t√¥ louca nessa airfrye...              1\n",
       "..                                                 ...            ...\n",
       "195  tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...              1\n",
       "196  pessoal daqui de casa inventou de querer fazer...              1\n",
       "197  eu nao sei voces, mas eu ganhei uma airfryer g...              1\n",
       "198  @ibebelly amanh√£ eu vou fazer um p√£o de alho d...              1\n",
       "199  disse pra vov√≥ que t√¥ estagiando e a mulher j√°...              1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "lista = []\r\n",
    "\r\n",
    "for linha in df_tudo['Tudo']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b) \r\n",
    "    lista.append(limpo)\r\n",
    "    \r\n",
    "serie = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\r\n",
    "df_tudo['Tudo'] = serie\r\n",
    "\r\n",
    "df_tudo.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter vai fazer compr airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o queij forno daqui casa bosta p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom aparentemente deu ruim saiu toda tinta / t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airfryer panelas polishop celebra anos descont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano t√¥ louca nessa airfryer serase boa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tudo  Classifica√ß√£o\n",
       "0                   twitter vai fazer compr airfryer              1\n",
       "1  quero assar p√£o queij forno daqui casa bosta p...              1\n",
       "2  bom aparentemente deu ruim saiu toda tinta / t...              1\n",
       "3  airfryer panelas polishop celebra anos descont...              0\n",
       "4            mano t√¥ louca nessa airfryer serase boa              1"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "def separa_dataframe(df):\r\n",
    "    train, test_new = train_test_split(df_tudo, test_size=200)\r\n",
    "    return train, test_new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "lista_da_acuracia = []\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    \r\n",
    "    datas = separa_dataframe(df_tudo)\r\n",
    "    train = datas[0]\r\n",
    "    test_new = datas[1]\r\n",
    "    df = classificador(test_new, test_new[\"Tudo\"])\r\n",
    "    tabela_nova = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)\r\n",
    "    acuracia = tabela_nova.iloc[1,1]*100 + tabela_nova.iloc[0,0]*100\r\n",
    "    lista_da_acuracia.append(acuracia)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "serie_acuracia = pd.Series(lista_da_acuracia)\r\n",
    "minimo = serie_acuracia.min()\r\n",
    "maximo = serie_acuracia.max()\r\n",
    "media = serie_acuracia.mean()\r\n",
    "\r\n",
    "\r\n",
    "print('O m√≠nimo de efic√°cia: {0:.2f} %'.format(minimo))\r\n",
    "print('O m√°ximo de efic√°cia: {0:.2f} %'.format(maximo))\r\n",
    "print('A m√©dia de efic√°cia: {0:.2f} %'.format(media))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O m√≠nimo de efic√°cia: 50.50 %\n",
      "O m√°ximo de efic√°cia: 64.50 %\n",
      "A m√©dia de efic√°cia: 57.34 %\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histograma com percentuais de acertos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "from numpy import arange\r\n",
    "import numpy as np\r\n",
    "faixa1 = arange(int(minimo)-5,int(maximo)+5,2.5)\r\n",
    "faixa1\r\n",
    "\r\n",
    "\r\n",
    "plt.hist(serie_acuracia, bins=faixa1, edgecolor='white', density = True)\r\n",
    "plt.title('Efic√°cia')\r\n",
    "plt.ylabel('Faixas')\r\n",
    "plt.xlabel('Porcentagem de acertos(%)')\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Porcentagem de acertos(%)')"
      ]
     },
     "metadata": {},
     "execution_count": 50
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Vantagens ou desvantagens sobre construir um classificador considerando uma √∫nica vez a divis√£o da base de dados em treinamento e em teste:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analisando o histograma das acur√°rias obtidas a partir de v√°rias bases de dados, percebe-se que h√° uma amplitude de 15% entre os valores m√°ximo e m√≠nimo de acur√°cia. Se tiv√©ssemos considerado essas novas bases de dados na constru√ß√£o do classificador, haveria uma propaga√ß√£o de erros e assim, a confiabilidade do modelo seria prejudicada. Al√©m disso, trabalhar com apenas uma base de dados de treinamento pode ser vantajoso por ser mais f√°cil encontrar os erros mais frequentes do classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Refer√™ncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56505bb563a3a8c3edae909efbbeba68d55f556b46955e58b7586a74f580b29e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}