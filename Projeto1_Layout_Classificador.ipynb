{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Camila Soares Magni\n",
    "\n",
    "Nome: Lincoln Rodrigo Pereira Melo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Etapas do desenvolvimento do projeto:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "source": [],
=======
   "source": [
    "Primeiramente, "
   ],
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\camil\\OneDrive\\√Årea de Trabalho\\INSPER\\2¬∞ sem\\C dados\\Projeto1- Cdados\\Proj1Cdados\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "filename = 'airfryer.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o twitter vai me fazer comprar uma airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o de queijo, mas o forno daqui d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom, aparentemente deu ruim e saiu toda a tint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de airfryer a panelas: polishop celebra 22 ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@danielsmarconn mano eu t√¥ louca nessa airfrye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0        o twitter vai me fazer comprar uma airfryer              1\n",
       "1  quero assar p√£o de queijo, mas o forno daqui d...              1\n",
       "2  bom, aparentemente deu ruim e saiu toda a tint...              1\n",
       "3  de airfryer a panelas: polishop celebra 22 ano...              0\n",
       "4  @danielsmarconn mano eu t√¥ louca nessa airfrye...              1"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 5
=======
     "execution_count": 4
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o bom da airfryer fica tudo pronto r√°pido, n√£o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um app pra calcular se √© mais barato fazer a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@raytotsukishiro aumentou o pre√ßo de tudo. aqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti um p√£o de queijo na airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@alcysio @safbf p√¥ alcysio, me adaptei total p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  o bom da airfryer fica tudo pronto r√°pido, n√£o...              1\n",
       "1  um app pra calcular se √© mais barato fazer a c...              0\n",
       "2  @raytotsukishiro aumentou o pre√ßo de tudo. aqu...              0\n",
       "3                meti um p√£o de queijo na airfryer üòå              1\n",
       "4  @alcysio @safbf p√¥ alcysio, me adaptei total p...              1"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 6
=======
     "execution_count": 5
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
<<<<<<< HEAD
    "## SOBRE O PRODUTO\n",
    "\n",
    "O produto escolhido foi a AirFryer : \"AirFryer ou air fryer √© um eletrodom√©stico usado para fritar alimentos. √â t√£o eficaz quanto uma fritadeira tradicional que usa √≥leo, mas n√£o utiliza a imers√£o em gorduras para a coc√ß√£o/para o cozimento dos alimentos.\"\n",
    "\n",
    "fonte : https://pt.wikipedia.org/wiki/Fritadeira_sem_%C3%B3leo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Com a escolha do produto, foram considerados relevantes os tweets que expressasem algum sentimento, seja ele positivo ou negativo, tweets que expressam vontade de adquirir o produto ou receitas que os usu√°rios compartilham.\n",
    "O restante dos tweets foram considerados irrelevantes, como tweets que usam do termo \"airfryer\" em outros sentidos que n√£o seja falando diretamente do produto (\"Parece que estou dentro de uma airfryer\").\n",
    "\n",
    "\n",
    "Texto velho :\n",
    "Escolhemos a fritadeira sem √≥leo ,airfryer, como nosso produto. Para a classifica√ß√£o dos tweets, consideramos todas as mensagens que expressam alguma opini√£o sobre o produto, sejam elogios , cr√≠ticas e receitas como relevantes, assim como as que falam sobre um desejo de adquirir uma airfryer. O resto foi classificado como irrelevante, incluindo mensagens sobre outros assuntos que n√£o fazem sentido para a an√°lise do produto(Exemplo: \"Parece que estou dentro de uma airfryer\"). "
=======
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos a fritadeira sem √≥leo airfryer como nosso produto. Para a classifica√ß√£o dos tweets, consideramos todas as mensagens que expressam alguma opini√£o sobre o produto, sejam elogios , cr√≠ticas e receitas como relevantes, assim como as que falam sobre um desejo de adquirir uma airfryer. O resto foi classificado como irrelevante, incluindo mensagens sobre outros assuntos que n√£o fazem sentido para a an√°lise do produto(Exemplo: \"Parece que estou dentro de uma airfryer\"). "
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador multinomial Na√Øve Bayes √© um dos modelos mais populares no aprendizado de m√°quina. Tomando como premissa a suposi√ß√£o de independ√™ncia entre as vari√°veis do problema, o modelo de Na√Øve Bayes realiza uma classifica√ß√£o probabil√≠stica de observa√ß√µes, caracterizando-as em classes pr√©-definidas. \n",
    "\n",
    "\n",
    "O algoritmo Na√Øve Bayes √© uma aplica√ß√£o direta do teorema hom√¥nimo. O termo na√Øve, (do ingl√™s, ing√™nuo) se refere √† premissa central do algoritmo de que os atributos considerados s√£o n√£o correlacionados entre si. \n",
    "\n",
    "fonte : https://www.digitalhouse.com/br/blog/naive-bayes\n",
    "\n",
    "\n",
    "Por exemplo, no classificador aqui montado, n√£o s√£o levada em contas express√µes e apenas as palavras isoladas.\n",
    "\n",
    "\n",
    "Explicando um pouco da constru√ß√£o do classificador:\n",
    "\n",
    "#### Eventos:\n",
    "$R$:   tweets relevantes\n",
    "\n",
    "$R^C$: tweets irrelevantes\n",
    "\n",
    "$U$ :  todos os tweets relacionados com airfryer coletados\n",
    "\n",
    "$P(R)$ -> Probabilidade de um tweet ser relevante\n",
    "\n",
    "$P(R^C)$ -> Probabilidade de um tweet ser irrelevante\n",
    "\n",
    "$P(R/Tweet)$ -> Probabilidade de ser relevante dado que √© um tweet relacionado com airfryer\n",
    "\n",
    "$P(R^C/Tweet)$ -> Probabilidade de ser irrelevante dado que √© um tweet relacionado com airfryer\n",
    "\n",
    "Lembre-se que $P(A/B) = P(B/A) * P(A) / P(B)$\n",
    "\n",
    "Note que ao utilizar Naive-Bayes, queremos apenas classificar como relevante ou irrelevante, ou seja\n",
    "\n",
    "Se calcularmos :\n",
    "\n",
    "$P(R/Tweet) = P(Tweet/R) * P(R) / P(Tweet)$   (i)\n",
    "\n",
    "e\n",
    "\n",
    "$P(R^C/Frase) = P(Tweet/R^c) * P(R^c) / P(Tweet)$ (ii)\n",
    "\n",
    "Logo, como para classificar fazemos uma compara√ß√£o entre  (i) e (ii), podemos desconsiderar os denominadores na conta.\n",
    "Portanto, para esse caso usaremos:\n",
    "\n",
    "$P(R/Tweet) = P(Tweet/R) * P(R)$\n",
    "\n",
    "$P(R^C/Frase) = P(Tweet/R^c) * P(R^c)$\n",
    "\n",
    "Com isso, olhando para a $P(Tweet/R) e P(Tweet/R^c).$\n",
    "\n",
    "Considerando Tweet = palavra1 palavra2 palavra3\n",
    "\n",
    "A nossa $P(Tweet/R) = P(palavra1/R) * P(palavra2/R) * P(palavra3/R)$\n",
    "e $P(Tweet/R^C) = P(palavra1/R^C) * P(palavra2/R^C) * P(palavra3/R^C)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suaviza√ß√£o de LaPlace:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seguindo a linha de racioc√≠nio de Naive-Bayes, caso uma palavra n√£o esteja presente no conjunto de palavras analisados, ent√£o ter√≠amos:\n",
    "\n",
    "$P(palavra/R)$ = 0\n",
    "\n",
    "e\n",
    "\n",
    "$P(palavra/R^C)$ = 0.\n",
    "\n",
    "Portanto se essa palavra estivesse em qualquer frase, a probabilidade dessa frase ser classificada seria zero.\n",
    "\n",
    "Para resolver essa situa√ß√£o surgiu a Suaviza√ß√£o de Laplace. Essa ideia se baseia em adicionar um em cada contagem para que o resultado do numerador nunca seja igual a zero. Al√©m disso, adicionar o n√∫mero de palavras poss√≠veis no denominador para balancear e garantir que a divis√£o nunca vai ser maior do que 1.\n",
    "\n",
    "Note que essa ideia ser√° aplicada na implementa√ß√£o da fun√ß√£o."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fun√ß√µes para a limpeza da base de dados:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from IPython.display import display\r\n",
    "import re \r\n",
    "import nltk\r\n",
    "\r\n",
    "# Fun√ß√£o de limpeza dos textos\r\n",
    "def cleanup(text):\r\n",
    "    punctuation = '[\"\"''!-.:?;‚Äú‚Äù~1234567890]'                            # sinais que queremos retirar do texto\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)                              # retira os sinais\r\n",
    "    text_subbed = re.sub(r\"http\\S+\", \"\", text_subbed)                    # retira os URL\r\n",
    "    text_subbed = re.sub('@[^\\s]+','',text_subbed,flags=re.MULTILINE)    # retira os nomes de usu√°rio\r\n",
    "    text_subbed = re.sub(r\"kk\\S+\", \"kk\", text_subbed)                    # transforma as strings que come√ßam com kk em 'kk'\r\n",
    "    text_subbed = re.sub(r\"compr\\S+\", \"compr\", text_subbed)              # transforma as strings que come√ßam com compr (radical do verbo comprar) em \"compr\"\r\n",
    "    text_subbed = re.sub(r\"limp\\S+\", \"limp\", text_subbed)                # transforma as strings que come√ßam com limp (radical do verbo limpar) em \"limp\"\r\n",
    "    text_subbed = re.sub(r\"aa\\S+\", \"\", text_subbed)                      # retira as strings que come√ßam com aa (normalmente alguma express√£o ou sequ√™ncia de letras sem sentido)\r\n",
    "    text_subbed = re.sub(r\"airfryer\\S+\", \"airfryer\", text_subbed)        # usado evitar que erros de escrita de palavras coladas com airfryer n√£o acontecam\r\n",
    "    text_subbed = re.sub(r\"queij\\S+\", \"queij\", text_subbed)              # para corrigir alguns erros de portugu√™s comuns dos usu√°rios dos tweets (receita recorrente)\r\n",
    "    text_subbed = re.sub(r\"batat\\S+\", \"batata\", text_subbed)             # transforma as strings que come√ßam com batat (radical da palavra batata) para evitar varia√ß√µes como \"Batatinhas\"\r\n",
    "    aux = nltk.TweetTokenizer()\r\n",
    "    text_subbed = aux.tokenize(text_subbed)                              # separa os emojis\r\n",
    "    string_final = ' '.join(text_subbed)                                 # string limpa\r\n",
=======
   "execution_count": 6,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import re \n",
    "import nltk\n",
    "\n",
    "# Fun√ß√£o de limpeza dos textos\n",
    "def cleanup(text):\n",
    "    punctuation = '[\"\"''!-.:?;‚Äú‚Äù~1234567890]'                            # sinais que queremos retirar do texto\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)                              # retira os sinais\n",
    "    text_subbed = re.sub(r\"http\\S+\", \"\", text_subbed)                    # retira os URL\n",
    "    text_subbed = re.sub('@[^\\s]+','',text_subbed,flags=re.MULTILINE)    # retira os nomes de usu√°rio\n",
    "    text_subbed = re.sub(r\"kk\\S+\", \"kk\", text_subbed)                    # transformar as strings que come√ßam com kk em 'kk'\n",
    "    text_subbed = re.sub(r\"compr\\S+\", \"compr\", text_subbed) \n",
    "    text_subbed = re.sub(r\"limp\\S+\", \"limp\", text_subbed) \n",
    "    text_subbed = re.sub(r\"aa\\S+\", \"\", text_subbed)\n",
    "    text_subbed = re.sub(r\"airfryer\\S+\", \"airfryer\", text_subbed)\n",
    "    text_subbed = re.sub(r\"queij\\S+\", \"queij\", text_subbed)\n",
    "    text_subbed = re.sub(r\"batat\\S+\", \"batata\", text_subbed) \n",
    "    aux = nltk.TweetTokenizer()\n",
    "    text_subbed = aux.tokenize(text_subbed)                              # separa os emojis\n",
    "    string_final = ' '.join(text_subbed)                                 # string limpa\n",
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    "    return string_final"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 7,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "# Fun√ß√£o para tirar as 'Stopwords' em portugu√™s:\n",
    "# nltk.download('stopwords') - INSTALAR, caso vc n√£o tenha instalado\n",
    "def retirar_stopwords(lista):\n",
    "    lista_limpa = []\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    for palavra in lista:\n",
    "        if palavra not in stopwords:\n",
    "            lista_limpa.append(palavra)\n",
    "    return lista_limpa"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realizando a limpeza da base de treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "source": [
    "lista = []\r\n",
    "for linha in train['Treinamento']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b)  \r\n",
    "    lista.append(limpo)\r\n",
    "    \r\n",
    "serie_train = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\r\n",
    "train['Treinamento'] = serie_train        # substitui os tweets originais da planilha, pelos tweets limpos\r\n",
=======
   "execution_count": 8,
   "source": [
    "lista = []\n",
    "for linha in train['Treinamento']:\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \n",
    "    a = limpo.split()\n",
    "    b = retirar_stopwords(a)\n",
    "    limpo = ' '.join(b)  \n",
    "    lista.append(limpo)\n",
    "    \n",
    "serie_train = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\n",
    "train['Treinamento'] = serie_train        # substitui os tweets originais da planilha, pelos tweets limpos\n",
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter vai fazer compr airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o queij forno daqui casa bosta p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom aparentemente deu ruim saiu toda tinta / t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airfryer panelas polishop celebra anos descont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano t√¥ louca nessa airfryer serase boa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0                   twitter vai fazer compr airfryer              1\n",
       "1  quero assar p√£o queij forno daqui casa bosta p...              1\n",
       "2  bom aparentemente deu ruim saiu toda tinta / t...              1\n",
       "3  airfryer panelas polishop celebra anos descont...              0\n",
       "4            mano t√¥ louca nessa airfryer serase boa              1"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 9
=======
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fun√ß√£o Classificadora Naive-Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def classificador(dataframe, series):                         #recebe o dataframe e a serie de tweets que ser√° classificada\n",
    "    \n",
    "    filtro = train.Classifica√ß√£o==1          # filtra os tweets classificados como relevantes\n",
    "    relevantes = train.loc[filtro, :]        # dataframe com tweets relevantes\n",
    "\n",
    "    filtro2 = train.Classifica√ß√£o==0        # filtra os tweets classificados como irrelevantes\n",
    "    irrelevantes = train.loc[filtro2, :]    # dataframe com tweets irrelevantes\n",
    "\n",
    "    # Transforma o dataframe relevantes em um √∫nico texto\n",
    "    string_relevante = ''\n",
    "    for linha in relevantes.iloc[:,0]:\n",
    "        string_relevante+= ' '+ linha\n",
    "\n",
    "    # Transforma o dataframe irrelevantes em um √∫nico texto\n",
    "    string_irrelevante = ''\n",
    "    for linha in irrelevantes.iloc[:,0]:\n",
    "        string_irrelevante+= ' '+ linha\n",
    "\n",
    "    todas_relevantes = string_relevante.split()        #Lista com todas as palavras que aparece na string relevante\n",
    "    todas_irrelevantes = string_irrelevante.split()    #Lista com todas as palavras que aparece na string irrelevante\n",
    "\n",
    "    serie_relevante = pd.Series(todas_relevantes)      #Transforma a lista de strings relevantes em um series\n",
    "    serie_irrelevante = pd.Series(todas_irrelevantes)  #Transforma a lista de strings irrelevantes em um series\n",
    "\n",
    "    todas = string_irrelevante + string_relevante          # juntando todas as palavras que aparecem na base de dados Treinamento\n",
    "    todas_as_palavras = todas.split()                      # lista com todas as palavras\n",
    "    serie_total = pd.Series(todas_as_palavras) \n",
    "    serie_total\n",
    "\n",
    "    P_R = len(todas_relevantes)/len(todas_as_palavras)        # probabilidade de uma palavra ser relevante\n",
    "    P_I = len(todas_irrelevantes)/len(todas_as_palavras)      # probabilidade de uma palavra ser irrelevante\n",
    "\n",
    "    freq_rel_absoluta = serie_relevante.value_counts()           # quantidade de cada palavra na serie relevante\n",
    "    freq_irrel_absoluta = serie_irrelevante.value_counts()       # quantidade de cada palavra na serie irrelevante\n",
    "    freq_tot_absoluta = serie_total.value_counts()               # quantidade de cada palavra na serie total\n",
    "\n",
    "\n",
    "    \n",
    "    classificados = []\n",
    "    for frase in series:\n",
    "        lista_palavras = frase.split()\n",
    "        lista_palavras = retirar_stopwords(lista_palavras)    #implementa fun√ß√£o que tira as stopwords\n",
    "        k,i = 0,0                                             #contador de palavras N√ÉO presentes em relevantes (k) e em irrevelantes (i)\n",
    "        for palavra in lista_palavras:\n",
    "            if palavra not in todas_relevantes: \n",
    "                k += 1\n",
    "            if palavra not in todas_irrelevantes:\n",
    "                i += 1\n",
    "\n",
    "        prob_frase_dado_relevante = 1\n",
    "        prob_frase_dado_irrelevante = 1\n",
    "\n",
    "        if k == 0:                                   #se tiver palavras no series que n√£o estao na nossa base de dados relevantes\n",
    "            for palavra in lista_palavras:\n",
    "                prob = freq_rel_absoluta[palavra] / freq_rel_absoluta.sum()\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\n",
    "\n",
    "        else:\n",
    "            for palavra in lista_palavras:\n",
    "                if palavra in freq_rel_absoluta:\n",
    "                    prob = (freq_rel_absoluta[palavra]+ 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta)) # SUAVIZA√á√ÉO DE LAPLACE\"\n",
    "                else: \n",
    "                    prob = (0 + 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta))\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\n",
    "        \n",
    "        if i == 0:\n",
    "            for palavra in lista_palavras:\n",
    "                prob = ( freq_irrel_absoluta[palavra] ) / (freq_irrel_absoluta.sum())\n",
    "                prob_frase_dado_irrelevante *= prob     \n",
    "\n",
    "        else:\n",
    "            for palavra in lista_palavras:\n",
    "                if palavra in freq_irrel_absoluta:\n",
    "                    prob = ( freq_irrel_absoluta[palavra]+ 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\n",
    "                else:\n",
    "                    prob = ( 0 + 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\n",
    "                prob_frase_dado_irrelevante *= prob         #multiplica a probabilidade de cada palavra dado frase\n",
    "                #multiplica a probabilidade de cada palavra dado frase\n",
    "                \n",
    "        probRdadoFrase = prob_frase_dado_relevante* P_R\n",
    "        probIdadoFrase = prob_frase_dado_irrelevante* P_I\n",
    "        \n",
    "        if probRdadoFrase > probIdadoFrase:\n",
    "            classificados.append(1)                         #classifica como relevante\n",
    "        else:  \n",
    "            classificados.append(0)                         #classifica como irrelevante\n",
    "    \n",
    "    serie_classificado = pd.Series(classificados)\n",
    "    novo_df = dataframe.iloc[:, [0,1]]\n",
    "    novo_df['Classificado'] = serie_classificado\n",
    "    return novo_df\n",
    "                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o bom da airfryer fica tudo pronto r√°pido, n√£o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um app pra calcular se √© mais barato fazer a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@raytotsukishiro aumentou o pre√ßo de tudo. aqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti um p√£o de queijo na airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@alcysio @safbf p√¥ alcysio, me adaptei total p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>pessoal daqui de casa inventou de querer fazer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu nao sei voces, mas eu ganhei uma airfryer g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@ibebelly amanh√£ eu vou fazer um p√£o de alho d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>disse pra vov√≥ que t√¥ estagiando e a mulher j√°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o\n",
       "0    o bom da airfryer fica tudo pronto r√°pido, n√£o...              1\n",
       "1    um app pra calcular se √© mais barato fazer a c...              0\n",
       "2    @raytotsukishiro aumentou o pre√ßo de tudo. aqu...              0\n",
       "3                  meti um p√£o de queijo na airfryer üòå              1\n",
       "4    @alcysio @safbf p√¥ alcysio, me adaptei total p...              1\n",
       "..                                                 ...            ...\n",
       "195  tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...              1\n",
       "196  pessoal daqui de casa inventou de querer fazer...              1\n",
       "197  eu nao sei voces, mas eu ganhei uma airfryer g...              1\n",
       "198  @ibebelly amanh√£ eu vou fazer um p√£o de alho d...              1\n",
       "199  disse pra vov√≥ que t√¥ estagiando e a mulher j√°...              1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "source": [
    "# Fun√ß√£o Classificadora Naive-Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na C√©lula abaixo est√° implementada a fun√ß√£o classificadora Naive-Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def classificador(dataframe, series):                         #recebe o dataframe e a serie de tweets que ser√° classificada\r\n",
    "#     contador = 0 \r\n",
    "    \r\n",
    "    filtro = train.Classifica√ß√£o==1          # filtra os tweets classificados como relevantes\r\n",
    "    relevantes = train.loc[filtro, :]        # dataframe com tweets relevantes\r\n",
    "\r\n",
    "    filtro2 = train.Classifica√ß√£o==0        # filtra os tweets classificados como irrelevantes\r\n",
    "    irrelevantes = train.loc[filtro2, :]    # dataframe com tweets irrelevantes\r\n",
    "\r\n",
    "    # Transforma o dataframe relevantes em um √∫nico texto\r\n",
    "    string_relevante = ''\r\n",
    "    for linha in relevantes.iloc[:,0]:\r\n",
    "        string_relevante+= ' '+ linha\r\n",
    "\r\n",
    "    # Transforma o dataframe irrelevantes em um √∫nico texto\r\n",
    "    string_irrelevante = ''\r\n",
    "    for linha in irrelevantes.iloc[:,0]:\r\n",
    "        string_irrelevante+= ' '+ linha\r\n",
    "\r\n",
    "    todas_relevantes = string_relevante.split()        #Lista com todas as palavras que aparece na string relevante\r\n",
    "    todas_irrelevantes = string_irrelevante.split()    #Lista com todas as palavras que aparece na string irrelevante\r\n",
    "\r\n",
    "    serie_relevante = pd.Series(todas_relevantes)      #Transforma a lista de strings relevantes em um series\r\n",
    "    serie_irrelevante = pd.Series(todas_irrelevantes)  #Transforma a lista de strings irrelevantes em um series\r\n",
    "\r\n",
    "    todas = string_irrelevante + string_relevante          # juntando todas as palavras que aparecem na base de dados Treinamento\r\n",
    "    todas_as_palavras = todas.split()                      # lista com todas as palavras\r\n",
    "    serie_total = pd.Series(todas_as_palavras) \r\n",
    "    serie_total\r\n",
    "\r\n",
    "    P_R = len(todas_relevantes)/len(todas_as_palavras)        # probabilidade de uma palavra ser relevante\r\n",
    "    P_I = len(todas_irrelevantes)/len(todas_as_palavras)      # probabilidade de uma palavra ser irrelevante\r\n",
    "\r\n",
    "    freq_rel_absoluta = serie_relevante.value_counts()           # quantidade de cada palavra na serie relevante\r\n",
    "    freq_irrel_absoluta = serie_irrelevante.value_counts()       # quantidade de cada palavra na serie irrelevante\r\n",
    "    freq_tot_absoluta = serie_total.value_counts()               # quantidade de cada palavra na serie total\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "    classificados = []\r\n",
    "    for frase in series:\r\n",
    "        lista_palavras = frase.split()\r\n",
    "        lista_palavras = retirar_stopwords(lista_palavras)    #implementa fun√ß√£o que tira as stopwords\r\n",
    "        k,i = 0,0                                             #contador de palavras N√ÉO presentes em relevantes (k) e em irrevelantes (i)\r\n",
    "        for palavra in lista_palavras:\r\n",
    "            if palavra not in todas_relevantes: \r\n",
    "                k += 1\r\n",
    "            if palavra not in todas_irrelevantes:\r\n",
    "                i += 1\r\n",
    "\r\n",
    "        prob_frase_dado_relevante = 1\r\n",
    "        prob_frase_dado_irrelevante = 1\r\n",
    "\r\n",
    "        if k == 0:                                   #se tiver palavras no series que n√£o estao na nossa base de dados relevantes\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                prob = freq_rel_absoluta[palavra] / freq_rel_absoluta.sum()\r\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\r\n",
    "\r\n",
    "        else:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                if palavra in freq_rel_absoluta:\r\n",
    "                    prob = (freq_rel_absoluta[palavra]+ 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta)) # SUAVIZA√á√ÉO DE LAPLACE\"\r\n",
    "                else: \r\n",
    "                    prob = (0 + 1 ) / (freq_rel_absoluta.sum()+ len(freq_tot_absoluta))\r\n",
    "                prob_frase_dado_relevante *= prob           #multiplica a probabilidade de cada palavra dado frase\r\n",
    "        \r\n",
    "        if i == 0:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                prob = ( freq_irrel_absoluta[palavra] ) / (freq_irrel_absoluta.sum())\r\n",
    "                prob_frase_dado_irrelevante *= prob     \r\n",
    "\r\n",
    "        else:\r\n",
    "            for palavra in lista_palavras:\r\n",
    "                if palavra in freq_irrel_absoluta:\r\n",
    "                    prob = ( freq_irrel_absoluta[palavra]+ 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\r\n",
    "                else:\r\n",
    "                    prob = ( 0 + 1 ) / (freq_irrel_absoluta.sum() +len(freq_tot_absoluta))\r\n",
    "                prob_frase_dado_irrelevante *= prob         #multiplica a probabilidade de cada palavra dado frase\r\n",
    "                #multiplica a probabilidade de cada palavra dado frase\r\n",
    "                \r\n",
    "        probRdadoFrase = prob_frase_dado_relevante* P_R\r\n",
    "        probIdadoFrase = prob_frase_dado_irrelevante* P_I\r\n",
    "        \r\n",
    "        if probRdadoFrase > probIdadoFrase:\r\n",
    "            classificados.append(1)                         #classifica como relevante\r\n",
    "        else:  \r\n",
    "            classificados.append(0)                         #classifica como irrelevante\r\n",
    "#         contador+=1\r\n",
    "#         print(classificados[len(classificados)-1] , contador)\r\n",
    "    \r\n",
    "    serie_classificado = pd.Series(classificados)\r\n",
    "    novo_df = dataframe.iloc[:, [0,1]]\r\n",
    "    novo_df = novo_df.reset_index(drop=True)\r\n",
    "    novo_df['Classificado'] = serie_classificado\r\n",
    "    return novo_df\r\n",
    "                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "lista = []\n",
    "\n",
<<<<<<< HEAD
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fazendo a limpeza na base de teste"
=======
    "for linha in test['Teste']:\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Teste e tira as letras mai√∫sculas\n",
    "    a = limpo.split()\n",
    "    b = retirar_stopwords(a)\n",
    "    limpo = ' '.join(b)  \n",
    "    lista.append(limpo)\n",
    "\n",
    "test['Teste'] = pd.Series(lista)             # Substitui os tweets originais da planilha, pelos tweets limpos\n",
    "test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bom airfryer fica tudo pronto r√°pido quero out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app pra calcular barato fazer comida airfryer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aumentou pre√ßo tudo aqui gente compr airfryer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti p√£o queij airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o\n",
       "0  bom airfryer fica tudo pronto r√°pido quero out...              1\n",
       "1  app pra calcular barato fazer comida airfryer ...              0\n",
       "2  aumentou pre√ßo tudo aqui gente compr airfryer ...              0\n",
       "3                          meti p√£o queij airfryer üòå              1\n",
       "4  p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...              1"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementando a fun√ß√£o..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "source": [
    "lista = []\r\n",
    "\r\n",
    "for linha in test['Teste']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Teste e tira as letras mai√∫sculas\r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b)  \r\n",
    "    lista.append(limpo)\r\n",
    "\r\n",
    "test['Teste'] = pd.Series(lista)             # Substitui os tweets originais da planilha, pelos tweets limpos\r\n",
    "test.head()"
=======
   "execution_count": 14,
   "source": [
    "df = test               # dataframe que ser√° argumento da fun√ß√£o classificadora\n",
    "series= test['Teste']   # series que ser√° argumento da fun√ß√£o classificadora"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Implementa fun√ß√£o\n",
    "df = classificador(df, series) #dataframe que passou pelo fun√ß√£o para classificar os tweets\n",
    "df.head()"
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bom airfryer fica tudo pronto r√°pido quero out...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app pra calcular barato fazer comida airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aumentou pre√ßo tudo aqui gente compr airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti p√£o queij airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...</td>\n",
       "      <td>1</td>\n",
<<<<<<< HEAD
=======
       "      <td>1</td>\n",
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                               Teste  Classifica√ß√£o\n",
       "0  bom airfryer fica tudo pronto r√°pido quero out...              1\n",
       "1  app pra calcular barato fazer comida airfryer ...              0\n",
       "2  aumentou pre√ßo tudo aqui gente compr airfryer ...              0\n",
       "3                          meti p√£o queij airfryer üòå              1\n",
       "4  p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...              1"
      ]
     },
     "metadata": {},
     "execution_count": 11
=======
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0  bom airfryer fica tudo pronto r√°pido quero out...              1   \n",
       "1  app pra calcular barato fazer comida airfryer ...              0   \n",
       "2  aumentou pre√ßo tudo aqui gente compr airfryer ...              0   \n",
       "3                          meti p√£o queij airfryer üòå              1   \n",
       "4  p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...              1   \n",
       "\n",
       "   Classificado  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "metadata": {},
     "execution_count": 15
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
<<<<<<< HEAD
    "# Implementando a fun√ß√£o..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df = test               # dataframe que ser√° argumento da fun√ß√£o classificadora\r\n",
    "series= test['Teste']   # series que ser√° argumento da fun√ß√£o classificadora"
=======
    "## Extraindo as contagens para verifica√ß√£o de performance"
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "source": [
    "# Implementa fun√ß√£o\r\n",
    "df = classificador(df, series) #dataframe que passou pelo fun√ß√£o para classificar os tweets\r\n",
    "df.head()"
=======
   "execution_count": 16,
   "source": [
    "tabela = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)  # tabela de porcentagens\n",
    "tabela"
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificado</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
<<<<<<< HEAD
       "      <td>app pra calcular barato fazer comida airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aumentou pre√ßo tudo aqui gente compr airfryer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meti p√£o queij airfryer üòå</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classifica√ß√£o  \\\n",
       "0  bom airfryer fica tudo pronto r√°pido quero out...              1   \n",
       "1  app pra calcular barato fazer comida airfryer ...              0   \n",
       "2  aumentou pre√ßo tudo aqui gente compr airfryer ...              0   \n",
       "3                          meti p√£o queij airfryer üòå              1   \n",
       "4  p√¥ alcysio adaptei total pra usar m√≠nimo g√°s a...              1   \n",
       "\n",
       "   Classificado  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extraindo as contagens para verifica√ß√£o de performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tabela = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)  # tabela de porcentagens\r\n",
    "tabela"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificado</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
=======
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
       "      <td>0.17</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classifica√ß√£o     0      1\n",
       "Classificado              \n",
       "0              0.28  0.095\n",
       "1              0.17  0.455"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 14
=======
     "execution_count": 16
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros positivos (mensagens relevantes e que s√£o\n",
    "classificadas como relevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 17,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "verdadeiros_positivos = tabela.iloc[1,1]*100\n",
    "verdadeiros_positivos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45.5"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 15
=======
     "execution_count": 17
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos positivos (mensagens irrelevantes e que s√£o classificadas\n",
    "como relevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 18,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "falsos_positivos = tabela.iloc[1,0]*100\n",
    "falsos_positivos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 16
=======
     "execution_count": 18
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros negativos (mensagens irrelevantes e que s√£o\n",
    "classificadas como irrelevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 19,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "verdadeiros_negativos = tabela.iloc[0,0]*100\n",
    "verdadeiros_negativos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28.000000000000004"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 17
=======
     "execution_count": 19
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos negativos (mensagens relevantes e que s√£o classificadas\n",
    "como irrelevantes)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 20,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "falsos_negativos = tabela.iloc[0,1]*100\n",
    "falsos_negativos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9.5"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 18
=======
     "execution_count": 20
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Acur√°cia (mensagens corretamente classificadas, independente da categoria)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 21,
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "source": [
    "acuracia = verdadeiros_positivos + verdadeiros_negativos\n",
    "acuracia"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "73.5"
      ]
     },
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 19
=======
     "execution_count": 21
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
    }
   ],
   "metadata": {}
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance do classificador e poss√≠veis melhorias  "
   ],
   "metadata": {}
  },
  {
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "cell_type": "markdown",
   "source": [
    "Comparativo qualitativo sobre os percentuais obtidos:\n",
    "\n",
    "A partir dos percentuais de verdadeiros positivos e negativos obtidos, observa-se que o nosso classificador possui acur√°cia de 73.5%, o que significa que dos 100% dos tweets, ter√≠amos 26.5% de falhas (falsos positivos e negativos).\n",
    "\n",
    "Analisando de maneira mais aprofundada todos os tweets classificados como relevantes (62.5% do total), temos que a porcentagem de verdadeiros positivos (45.5%) √© mais que o dobro do que a de falsos positivos (17%). Em outras palavras, 72.8% dos tweets classificados como relevantes, foram classificados corretamente. \n",
    "\n",
    "Da mesma forma, olhando para os tweets classificados como irrelevantes (37.5% do total, temos 28% de acertos, ou seja, 74,6% dos tweets classificados como irrelevantes.\n",
    "\n",
    "As mensagens com sarcasmo ou dupla nega√ß√£o s√£o tratadas pelo classificador da mesma forma que qualquer outra mensagem, isto √©, pela an√°lise das probabilidades de cada palavra do tweet. Ent√£o, algumas s√£o classificadas corretamente e outras, n√£o, j√° que muitas palavras aparecem na Base de Treinamento como relevantes. \n",
    "\n",
    "Dessa forma, levando em considera√ß√£o os percentuais obtidos, consideramos que a performance do nosso classificador est√° aceit√°vel, por√©m h√° algumas melhorias que poderiam ser implementadas, como .....\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
<<<<<<< HEAD
    "#### Performance do classificador e poss√≠veis melhorias  "
=======
    "#### Por que continuar financiando o projeto? "
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
<<<<<<< HEAD
    "Comparativo qualitativo sobre os percentuais obtidos:\n",
    "\n",
    "A partir dos percentuais de verdadeiros positivos e negativos obtidos, observa-se que o nosso classificador possui acur√°cia de 73.5%, o que significa que dos 100% dos tweets, ter√≠amos 26.5% de falhas (falsos positivos e negativos).\n",
    "\n",
    "Analisando de maneira mais aprofundada todos os tweets classificados como relevantes (62.5% do total), temos que a porcentagem de verdadeiros positivos (45.5%) √© mais que o dobro do que a de falsos positivos (17%). Em outras palavras, 72.8% dos tweets classificados como relevantes, foram classificados corretamente. \n",
    "\n",
    "Da mesma forma, olhando para os tweets classificados como irrelevantes (37.5% do total, temos 28% de acertos, ou seja, 74,6% dos tweets classificados como irrelevantes.\n",
    "\n",
    "As mensagens com sarcasmo ou dupla nega√ß√£o s√£o tratadas pelo classificador da mesma forma que qualquer outra mensagem, isto √©, pela an√°lise das probabilidades de cada palavra do tweet. Ent√£o, algumas s√£o classificadas corretamente e outras, n√£o, j√° que muitas palavras aparecem na Base de Treinamento como relevantes. \n",
    "\n",
    "Dessa forma, levando em considera√ß√£o os percentuais obtidos, consideramos que a performance do nosso classificador est√° aceit√°vel, por√©m h√° algumas melhorias que poderiam ser implementadas, como .....\n",
    "\n",
    "\n",
    "\n"
=======
    "O projeto deve continuar sendo financiado, porque a partir dele, √© poss√≠vel entender os interesses e as opini√µes do p√∫blico alvo da empresa, assim como elogios e cr√≠ticas ao produto, para que seja poss√≠vel implementar melhorias em pontos com maiores reclama√ß√µes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se n√≥s alimentarmos a base de Treinamento utilizando o pr√≥prio classificador, o percentual de erros aumentaria significativamente. Isso porque, os erros do classificador se propagariam para a classifica√ß√£o da base Treinamento, que por sua vez, alimentaria a classifica√ß√£o de novas bases, propagando cada vez mais os erros"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Diferentes cen√°rios de uso para o classificador Naive-Bayes "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador Naive-Bayes pode ser aplicado em diversas situa√ß√µes diferentes, como no diagnostico de doen√ßas ...."
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Por que continuar financiando o projeto? "
   ],
   "metadata": {}
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "source": [
    "O projeto deve continuar sendo financiado, porque a partir dele, √© poss√≠vel entender os interesses e as opini√µes do p√∫blico alvo da empresa, assim como elogios e cr√≠ticas ao produto, para que seja poss√≠vel implementar melhorias em pontos com maiores reclama√ß√µes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?"
   ],
=======
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "test = pd.read_excel(filename, sheet_name = \"Teste\" )\n",
    "test_novo_tudo = test.rename(columns={ \"Teste\" : \"Tudo\"})\n",
    "\n",
    "train = pd.read_excel(filename,sheet_name = \"Treinamento\")\n",
    "train_novo_tudo = train.rename(columns={ \"Treinamento\" : \"Tudo\" })\n",
    "\n",
    "df_tudo = pd.concat([train_novo_tudo,test_novo_tudo])\n",
    "df_tudo"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o twitter vai me fazer comprar uma airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o de queijo, mas o forno daqui d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom, aparentemente deu ruim e saiu toda a tint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de airfryer a panelas: polishop celebra 22 ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@danielsmarconn mano eu t√¥ louca nessa airfrye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>pessoal daqui de casa inventou de querer fazer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu nao sei voces, mas eu ganhei uma airfryer g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@ibebelly amanh√£ eu vou fazer um p√£o de alho d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>disse pra vov√≥ que t√¥ estagiando e a mulher j√°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tudo  Classifica√ß√£o\n",
       "0          o twitter vai me fazer comprar uma airfryer              1\n",
       "1    quero assar p√£o de queijo, mas o forno daqui d...              1\n",
       "2    bom, aparentemente deu ruim e saiu toda a tint...              1\n",
       "3    de airfryer a panelas: polishop celebra 22 ano...              0\n",
       "4    @danielsmarconn mano eu t√¥ louca nessa airfrye...              1\n",
       "..                                                 ...            ...\n",
       "195  tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...              1\n",
       "196  pessoal daqui de casa inventou de querer fazer...              1\n",
       "197  eu nao sei voces, mas eu ganhei uma airfryer g...              1\n",
       "198  @ibebelly amanh√£ eu vou fazer um p√£o de alho d...              1\n",
       "199  disse pra vov√≥ que t√¥ estagiando e a mulher j√°...              1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "lista = []\n",
    "\n",
    "for linha in df_tudo['Tudo']:\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \n",
    "    a = limpo.split()\n",
    "    b = retirar_stopwords(a)\n",
    "    limpo = ' '.join(b) \n",
    "    lista.append(limpo)\n",
    "    \n",
    "serie = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\n",
    "df_tudo['Tudo'] = serie\n",
    "\n",
    "df_tudo.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter vai fazer compr airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o queij forno daqui casa bosta p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom aparentemente deu ruim saiu toda tinta / t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airfryer panelas polishop celebra anos descont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano t√¥ louca nessa airfryer serase boa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tudo  Classifica√ß√£o\n",
       "0                   twitter vai fazer compr airfryer              1\n",
       "1  quero assar p√£o queij forno daqui casa bosta p...              1\n",
       "2  bom aparentemente deu ruim saiu toda tinta / t...              1\n",
       "3  airfryer panelas polishop celebra anos descont...              0\n",
       "4            mano t√¥ louca nessa airfryer serase boa              1"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def separa_dataframe(df):\n",
    "    train, test_new = train_test_split(df_tudo, test_size=200)\n",
    "    return train, test_new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "lista_da_acuracia = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    datas = separa_dataframe(df_tudo)\n",
    "    train = datas[0]\n",
    "    test_new = datas[1]\n",
    "    df = classificador(test_new, test_new[\"Tudo\"])\n",
    "    \n",
    "    tabela_nova = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)\n",
    "    acuracia = tabela_nova.iloc[1,1]*100 + tabela_nova.iloc[0,0]*100\n",
    "    lista_da_acuracia.append(acuracia)\n",
    "    \n",
    "print(lista_da_acuracia)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Classificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>libido alta baixa</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>amantes airfryer perdoem batata frita √≥leo pis...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>compr airfryer pro homem agora impar√°veis p√£o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fiz p√£o alho meio live esqueci airfryer üëç</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>airfryer forno sandu√≠che fica seco</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lembrei airfryer agora todos problemas vida su...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>lado bom ser pessoa boazinha empresta cart√£o p...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o queij forno daqui casa bosta p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cama sof√° novo chegaram aqui apto final semana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>anonymous vaza a√≠ quero airfryer</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tudo  Classifica√ß√£o  \\\n",
       "72                                   libido alta baixa              1   \n",
       "263  amantes airfryer perdoem batata frita √≥leo pis...              1   \n",
       "183  compr airfryer pro homem agora impar√°veis p√£o ...              1   \n",
       "30           fiz p√£o alho meio live esqueci airfryer üëç              1   \n",
       "186                 airfryer forno sandu√≠che fica seco              0   \n",
       "..                                                 ...            ...   \n",
       "32   lembrei airfryer agora todos problemas vida su...              0   \n",
       "278  lado bom ser pessoa boazinha empresta cart√£o p...              1   \n",
       "1    quero assar p√£o queij forno daqui casa bosta p...              1   \n",
       "34   cama sof√° novo chegaram aqui apto final semana...              0   \n",
       "164                   anonymous vaza a√≠ quero airfryer              1   \n",
       "\n",
       "     Classificado  \n",
       "72            1.0  \n",
       "263           NaN  \n",
       "183           1.0  \n",
       "30            0.0  \n",
       "186           0.0  \n",
       "..            ...  \n",
       "32            1.0  \n",
       "278           NaN  \n",
       "1             0.0  \n",
       "34            0.0  \n",
       "164           1.0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histograma com percentuais de acertos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
<<<<<<< HEAD
    "Se n√≥s alimentarmos a base de Treinamento utilizando o pr√≥prio classificador, o percentual de erros aumentaria significativamente. Isso porque, os erros do classificador se propagariam para a classifica√ß√£o da base Treinamento, que por sua vez, alimentaria a classifica√ß√£o de novas bases, propagando cada vez mais os erros, o que tornaria o modelo cada vez mais impreciso"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Diferentes cen√°rios de uso para o classificador Naive-Bayes "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador Naive-Bayes pode ser aplicado em diversas situa√ß√µes diferentes, como no diagn√≥stico de doen√ßas ( Considerando os verdadeiros (positivos e negativos) e falsos (positivos e negativos) , na identifica√ß√£o de mensagens de spam nos emails, protegendo os usu√°rios de um poss√≠vel golpe e otimizando o tempo passado no email e  numa alimenta√ß√£o de um algoritmo para sugerir conte√∫do baseado nas palavras buscadas pelo usu√°rio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
=======
    "##### Vantagens ou desvantagens sobre construir um classificador considerando uma √∫nica vez a divis√£o da base de dados em treinamento e em teste:\n"
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "source": [
    "test = pd.read_excel(filename, sheet_name = \"Teste\" )\r\n",
    "test_novo_tudo = test.rename(columns={ \"Teste\" : \"Tudo\"})\r\n",
    "\r\n",
    "train = pd.read_excel(filename,sheet_name = \"Treinamento\")\r\n",
    "train_novo_tudo = train.rename(columns={ \"Treinamento\" : \"Tudo\" })\r\n",
    "\r\n",
    "df_tudo = pd.concat([train_novo_tudo,test_novo_tudo])\r\n",
    "df_tudo = df_tudo.dropna(axis=1)\r\n",
    "df_tudo"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o twitter vai me fazer comprar uma airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o de queijo, mas o forno daqui d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom, aparentemente deu ruim e saiu toda a tint...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de airfryer a panelas: polishop celebra 22 ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@danielsmarconn mano eu t√¥ louca nessa airfrye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>pessoal daqui de casa inventou de querer fazer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu nao sei voces, mas eu ganhei uma airfryer g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@ibebelly amanh√£ eu vou fazer um p√£o de alho d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>disse pra vov√≥ que t√¥ estagiando e a mulher j√°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tudo  Classifica√ß√£o\n",
       "0          o twitter vai me fazer comprar uma airfryer              1\n",
       "1    quero assar p√£o de queijo, mas o forno daqui d...              1\n",
       "2    bom, aparentemente deu ruim e saiu toda a tint...              1\n",
       "3    de airfryer a panelas: polishop celebra 22 ano...              0\n",
       "4    @danielsmarconn mano eu t√¥ louca nessa airfrye...              1\n",
       "..                                                 ...            ...\n",
       "195  tutorial bolinha de queijo‚ú®\\n\\n200g de queijo ...              1\n",
       "196  pessoal daqui de casa inventou de querer fazer...              1\n",
       "197  eu nao sei voces, mas eu ganhei uma airfryer g...              1\n",
       "198  @ibebelly amanh√£ eu vou fazer um p√£o de alho d...              1\n",
       "199  disse pra vov√≥ que t√¥ estagiando e a mulher j√°...              1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "lista = []\r\n",
    "\r\n",
    "for linha in df_tudo['Tudo']:\r\n",
    "    limpo = cleanup(linha.lower())             # Limpa a planilha Treinamento e tira as letras mai√∫sculas \r\n",
    "    a = limpo.split()\r\n",
    "    b = retirar_stopwords(a)\r\n",
    "    limpo = ' '.join(b) \r\n",
    "    lista.append(limpo)\r\n",
    "    \r\n",
    "serie = pd.Series(lista)                 # Transforma a coluna da planilha Treinamento em Series\r\n",
    "df_tudo['Tudo'] = serie\r\n",
    "\r\n",
    "df_tudo.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tudo</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter vai fazer compr airfryer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quero assar p√£o queij forno daqui casa bosta p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bom aparentemente deu ruim saiu toda tinta / t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airfryer panelas polishop celebra anos descont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano t√¥ louca nessa airfryer serase boa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tudo  Classifica√ß√£o\n",
       "0                   twitter vai fazer compr airfryer              1\n",
       "1  quero assar p√£o queij forno daqui casa bosta p...              1\n",
       "2  bom aparentemente deu ruim saiu toda tinta / t...              1\n",
       "3  airfryer panelas polishop celebra anos descont...              0\n",
       "4            mano t√¥ louca nessa airfryer serase boa              1"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "def separa_dataframe(df):\r\n",
    "    train, test_new = train_test_split(df_tudo, test_size=200)\r\n",
    "    return train, test_new"
   ],
=======
   "execution_count": null,
   "source": [],
>>>>>>> fdcdf5ecc2afdc9c1e749d394b1b523003a53ad8
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "lista_da_acuracia = []\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    \r\n",
    "    datas = separa_dataframe(df_tudo)\r\n",
    "    train = datas[0]\r\n",
    "    test_new = datas[1]\r\n",
    "    df = classificador(test_new, test_new[\"Tudo\"])\r\n",
    "    tabela_nova = pd.crosstab(df.Classificado, df.Classifica√ß√£o, normalize= True)\r\n",
    "    acuracia = tabela_nova.iloc[1,1]*100 + tabela_nova.iloc[0,0]*100\r\n",
    "    lista_da_acuracia.append(acuracia)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "serie_acuracia = pd.Series(lista_da_acuracia)\r\n",
    "minimo = serie_acuracia.min()\r\n",
    "maximo = serie_acuracia.max()\r\n",
    "media = serie_acuracia.mean()\r\n",
    "\r\n",
    "\r\n",
    "print('O m√≠nimo de efic√°cia: {0:.2f} %'.format(minimo))\r\n",
    "print('O m√°ximo de efic√°cia: {0:.2f} %'.format(maximo))\r\n",
    "print('A m√©dia de efic√°cia: {0:.2f} %'.format(media))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O m√≠nimo de efic√°cia: 49.50 %\n",
      "O m√°ximo de efic√°cia: 63.00 %\n",
      "A m√©dia de efic√°cia: 57.12 %\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histograma com percentuais de acertos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from numpy import arange\r\n",
    "import numpy as np\r\n",
    "faixa1 = arange(int(minimo),int(maximo),1)\r\n",
    "faixa1\r\n",
    "\r\n",
    "\r\n",
    "plt.subplot(121)\r\n",
    "plt.hist(serie_acuracia, bins=faixa1, edgecolor='white', density = True)\r\n",
    "plt.title('Efic√°cia')\r\n",
    "plt.ylabel('Faixas')\r\n",
    "plt.xlabel('Porcentagem de acertos(%)')\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Porcentagem de acertos(%)')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Vantagens ou desvantagens sobre construir um classificador considerando uma √∫nica vez a divis√£o da base de dados em treinamento e em teste:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Percebemos que temos uma amplitude de 15% entre o m√°ximo e m√≠nimo de acur√°cia quando fizemos esses testes com v√°rias bases de dados de treinamento e testes. E com essa vari√¢ncia no valor da acur√°cia se para construir o classificador fosse considerado essas novas bases de dados de treinamento os erros de uma acabaria por se manter, o que resultaria numa propaga√ß√£o de erros o que iria diminuir a confiabilidade desse modelo classificador"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Refer√™ncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f50e35bdfd64427891e85d688af0f5548a53b16a35d85a3a857b2e66ca04f44"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}